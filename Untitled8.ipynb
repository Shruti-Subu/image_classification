{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkzM6GhvNnZeaNLJ2Urjt1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shruti-Subu/transliteration/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA-qzZT62eA2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIdC3ePV2pbE",
        "outputId": "178d4e18-72f0-4473-e107-e7d61b8c6539"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfE9ilPx2tCo"
      },
      "source": [
        "test=\"https://github.com/Shruti-Subu/transliteration/blob/main/NEWS2012-Ref-EnHi-1000.xml\"\n",
        "train=\"https://github.com/Shruti-Subu/transliteration/blob/main/NEWS2012-Training-EnHi-13937.xml\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94bDWuFt6lGY"
      },
      "source": [
        "test_dataset=\"/content/NEWS2012-Ref-EnHi-1000.xml\"\n",
        "train_dataset=\"/content/NEWS2012-Training-EnHi-13937.xml\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3NtOGOJ7Kan"
      },
      "source": [
        "# **DATA MANAGEMENT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t21SNjt-7S47"
      },
      "source": [
        "**ALPHABET SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-iePfMt6x_f",
        "outputId": "4229a408-9d0a-417e-f0bd-7ba7a2946e97"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "eng_alpha2index={pad_char:0}\n",
        "for index,alpha in enumerate(eng_alphabets):\n",
        "  eng_alpha2index[alpha]=index+1\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLFCujAV7yqQ",
        "outputId": "d2941286-68c7-4d6e-a411-69eca7af6144"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432.\n",
        "hindi_alphabets=[chr(alpha) for alpha in range(2304,2432)]\n",
        "hindi_alphabet_size=len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index={pad_char:0}\n",
        "for index,alpha in enumerate(hindi_alphabets):\n",
        "  hindi_alpha2index[alpha]=index+1\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN5BD_6i8lg3"
      },
      "source": [
        "**HELPER FUNCTION FOR DATA PRE-PROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goPO91-d8e5g"
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1IBzjBo95eP"
      },
      "source": [
        "**DATASET LOADING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsCWa8XG9s3k"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5lv_P_pC7pB",
        "outputId": "d16fc690-406c-4cb7-8f27-c85b5d19f123"
      },
      "source": [
        "train_dl=TransliterationDataLoader(train_dataset)\n",
        "test_dl=TransliterationDataLoader(test_dataset)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwAQPrBADUdo",
        "outputId": "df508adf-5883-4e9a-d841-26c2e8f2f04e"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_dl))\n",
        "print(\"Test Set Size:\\t\", len(test_dl))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_dl.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "PINJRA - पिंजरा\n",
            "EMIR - एमिर\n",
            "KAZMAIER - कज़्मायर\n",
            "LAIRD - लैर्ड\n",
            "LOWER - लोवर\n",
            "KALIYAN - कलियाँ\n",
            "PARAM - परम\n",
            "SUGAR - शुगर\n",
            "JACLYN - जैकलिन\n",
            "GRANT - ग्रांट\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg88UZCGF7Xe"
      },
      "source": [
        "# **ENCODING THE WORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaHfbNgHD8F-"
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdXOD6H5HrZV",
        "outputId": "906b1cc2-10eb-4dd0-ecf5-3b94c20a0cda"
      },
      "source": [
        "eng, hindi = train_dl.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NAVEED tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MWKaTcSHu2d",
        "outputId": "0862b874-f984-4f23-c5d8-0df099db9465"
      },
      "source": [
        "hindi_rep=gt_rep(hindi,hindi_alpha2index)\n",
        "print(hindi,hindi_rep)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "नवीद tensor([[41],\n",
            "        [54],\n",
            "        [65],\n",
            "        [39],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl1sf6niJMBL"
      },
      "source": [
        "# **NETWORK ARCHITECTURE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NferhDp7JU4Q"
      },
      "source": [
        "**ENCODER DECODER(GRU)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S265ViopIA6L"
      },
      "source": [
        "MAX_OUTPUT_CHAR=30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,hidden_size,output_size,verbose=False):\n",
        "     super(Transliteration_EncoderDecoder,self).__init__()\n",
        "     self.hidden_size=hidden_size\n",
        "     self.output_size=output_size\n",
        "\n",
        "     self.encoder_rnn_cell=nn.GRU(input_size,hidden_size)\n",
        "     self.decode_rnn_cell=nn.GRU(output_size,hidden_size)\n",
        "\n",
        "     self.h2o=nn.Linear(hidden_size,output_size)\n",
        "     self.softmax=nn.LogSoftmax(dim=2)\n",
        "     \n",
        "     self.verbose=verbose\n",
        "\n",
        "  def forward(self,input,max_output_char=MAX_OUTPUT_CHAR,device='cpu',ground_truth=None):\n",
        "      #encoder\n",
        "      out,hidden=self.encoder_rnn_cell(input)\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Encoder input', input.shape)\n",
        "        print('Encoder output', out.shape)\n",
        "        print('Encoder hidden', hidden.shape)\n",
        "\n",
        "        #decoder\n",
        "      decoder_state=hidden\n",
        "      decoder_input=torch.zeros(1,1,self.output_size).to(device)\n",
        "      output=[]\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder input ',decoder_input.shape)\n",
        "        print('Decoder state ',decoder_state.shape)\n",
        "\n",
        "      for i in range(max_output_char):\n",
        "        out,decoder_state=self.decode_rnn_cell(decoder_input,decoder_state)\n",
        "\n",
        "        if self.verbose:\n",
        "          print('Decoder intermediate output ',out.shape)\n",
        "        \n",
        "        out=self.h2o(decoder_state)\n",
        "        out=self.softmax(out)\n",
        "        output.append(out.view(1,-1))\n",
        "\n",
        "        if self.verbose:\n",
        "          print('decoder output ',out.shape)\n",
        "          self.verbose=False\n",
        "\n",
        "        max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "        if not ground_truth is None:\n",
        "          max_idx=ground_truth[i].reshape(1,1,1)\n",
        "        \n",
        "        one_hot=torch.FloatTensor(out.shape).to(device)\n",
        "        one_hot.zero_()\n",
        "        one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "        decoder_input=one_hot.detach()\n",
        "      return output\n",
        "\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUNDC0--SJcZ"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKsUk7uLSX2B"
      },
      "source": [
        "# unlike fully connceted or CNN model , we have to write an inference routine in case of sequence model.\n",
        "def infer(net, eng_word,shape,device ='cpu'):\n",
        "    # net.eval()\n",
        "    input_ = word_rep(eng_word,eng_alpha2index,device) # convert the name into one hot encoding.\n",
        "    outputs = net(input_,shape,device) # initilise the hidden layer.\n",
        "    \n",
        "    return outputs"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF772OsESbQj",
        "outputId": "d70d2c25-b57b-4df5-cda4-e8370bb32228"
      },
      "source": [
        "out = infer(net, 'INDIA', 30)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder input  torch.Size([1, 1, 129])\n",
            "Decoder state  torch.Size([1, 1, 256])\n",
            "Decoder intermediate output  torch.Size([1, 1, 256])\n",
            "decoder output  torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl7FBb_USePd",
        "outputId": "683762c6-433f-41ba-a07c-5061cd381420"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ख\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n",
            "torch.Size([1, 129]) ९\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qb5YIRwTCSR"
      },
      "source": [
        "#**TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEWVs2glTIzX"
      },
      "source": [
        "**CORE TRAINER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEUx5iE4S1si"
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_dl.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLCXL2Z0T1Ka"
      },
      "source": [
        "**TRAIN HELPER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypZf78lUTy2n"
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrM5upOHUN4d"
      },
      "source": [
        "**TRAINING WITHOUT ATTENTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNyNfPXuUI40"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "V_QAcvOWUXay",
        "outputId": "a38df2e3-1cee-4a91-d093-860b6369be9b"
      },
      "source": [
        "train_setup(net, lr=0.01, n_batches=2500, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 2499 Loss 0.09313002228736877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.53366345, 0.5008986 , ..., 0.09312654, 0.09313002,\n",
              "       0.09311984])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X-xG64nW4w5"
      },
      "source": [
        "#**INFERENCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX3fHUFeUuHK"
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_dl)):\n",
        "        eng, hindi = test_dl[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_dl)\n",
        "    return accuracy"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiXuy2cwYNTp",
        "outputId": "2a4a9ce3-fa7a-49cd-f9a3-2fe30f785e7c"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "#accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  69.65866605616606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGoUDxJ1YSvs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOMNZIwPuhWrdR6upI3xtU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shruti-Subu/transliteration/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA-qzZT62eA2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIdC3ePV2pbE",
        "outputId": "7a421080-0ad9-4c53-fe05-32fc1f58e7fb"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94bDWuFt6lGY"
      },
      "source": [
        "test_dataset=\"NEWS2012-Ref-EnHi-1000.xml\"\n",
        "train_dataset=\"NEWS2012-Training-EnHi-13937.xml\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3NtOGOJ7Kan"
      },
      "source": [
        "# **DATA MANAGEMENT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t21SNjt-7S47"
      },
      "source": [
        "**ALPHABET SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-iePfMt6x_f",
        "outputId": "7a109a15-928c-4e5f-a8eb-da7f95440ebc"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "eng_alpha2index={pad_char:0}\n",
        "for index,alpha in enumerate(eng_alphabets):\n",
        "  eng_alpha2index[alpha]=index+1\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLFCujAV7yqQ",
        "outputId": "31c4d7a5-eea4-4e64-cab0-011be1592064"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432.\n",
        "hindi_alphabets=[chr(alpha) for alpha in range(2304,2432)]\n",
        "hindi_alphabet_size=len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index={pad_char:0}\n",
        "for index,alpha in enumerate(hindi_alphabets):\n",
        "  hindi_alpha2index[alpha]=index+1\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN5BD_6i8lg3"
      },
      "source": [
        "**HELPER FUNCTION FOR DATA PRE-PROCESSING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goPO91-d8e5g"
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1IBzjBo95eP"
      },
      "source": [
        "**DATASET LOADING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsCWa8XG9s3k"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5lv_P_pC7pB",
        "outputId": "954fa270-0b74-4704-9284-17b229aaecd3"
      },
      "source": [
        "train_dl=TransliterationDataLoader(train_dataset)\n",
        "test_dl=TransliterationDataLoader(test_dataset)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwAQPrBADUdo",
        "outputId": "a4df29c1-1d0f-4403-d4a2-0c77b016cb77"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_dl))\n",
        "print(\"Test Set Size:\\t\", len(test_dl))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_dl.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20543\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "SANTOSH - संतोष\n",
            "GANGAA - गंगा\n",
            "LANDON - लंदन\n",
            "CITY - सिटी\n",
            "GOLA - गोला\n",
            "NALVADI - नलवाडी\n",
            "BANK - बैंक\n",
            "AMALATAAS - अमलतास\n",
            "RASHAD - रशाद\n",
            "TRIPURASUNDARI - त्रिपुरसुन्दरी\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg88UZCGF7Xe"
      },
      "source": [
        "# **ENCODING THE WORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaHfbNgHD8F-"
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdXOD6H5HrZV",
        "outputId": "8d03f2dd-6562-435b-9036-ee30eb441d90"
      },
      "source": [
        "eng, hindi = train_dl.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FORT tensor([[[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MWKaTcSHu2d",
        "outputId": "b2dcfe01-6e75-4552-fe4a-8b0dd8ea48f4"
      },
      "source": [
        "hindi_rep=gt_rep(hindi,hindi_alpha2index)\n",
        "print(hindi,hindi_rep)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "फोर्ट tensor([[44],\n",
            "        [76],\n",
            "        [49],\n",
            "        [78],\n",
            "        [32],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl1sf6niJMBL"
      },
      "source": [
        "# **NETWORK ARCHITECTURE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu4K7QsR9JAQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NferhDp7JU4Q"
      },
      "source": [
        "**ENCODER DECODER(GRU) without Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S265ViopIA6L"
      },
      "source": [
        "MAX_OUTPUT_CHAR=30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,hidden_size,output_size,verbose=False):\n",
        "     super(Transliteration_EncoderDecoder,self).__init__()\n",
        "     self.hidden_size=hidden_size\n",
        "     self.output_size=output_size\n",
        "\n",
        "     self.encoder_rnn_cell=nn.GRU(input_size,hidden_size)\n",
        "     self.decode_rnn_cell=nn.GRU(output_size,hidden_size)\n",
        "\n",
        "     self.h2o=nn.Linear(hidden_size,output_size)\n",
        "     self.softmax=nn.LogSoftmax(dim=2)\n",
        "     \n",
        "     self.verbose=verbose\n",
        "\n",
        "  def forward(self,input,max_output_char=MAX_OUTPUT_CHAR,device='cpu',ground_truth=None):\n",
        "      #encoder\n",
        "      out,hidden=self.encoder_rnn_cell(input)\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Encoder input', input.shape)\n",
        "        print('Encoder output', out.shape)\n",
        "        print('Encoder hidden', hidden.shape)\n",
        "\n",
        "        #decoder\n",
        "      decoder_state=hidden\n",
        "      decoder_input=torch.zeros(1,1,self.output_size).to(device)\n",
        "      output=[]\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder input ',decoder_input.shape)\n",
        "        print('Decoder state ',decoder_state.shape)\n",
        "\n",
        "      for i in range(max_output_char):\n",
        "        out,decoder_state=self.decode_rnn_cell(decoder_input,decoder_state)\n",
        "\n",
        "        if self.verbose:\n",
        "          print('Decoder intermediate output ',out.shape)\n",
        "        \n",
        "        out=self.h2o(decoder_state)\n",
        "        out=self.softmax(out)\n",
        "        output.append(out.view(1,-1))\n",
        "\n",
        "        if self.verbose:\n",
        "          print('decoder output ',out.shape)\n",
        "          self.verbose=False\n",
        "\n",
        "        max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "        if not ground_truth is None:\n",
        "          max_idx=ground_truth[i].reshape(1,1,1)\n",
        "        \n",
        "        one_hot=torch.FloatTensor(out.shape).to(device)\n",
        "        one_hot.zero_()\n",
        "        one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "        decoder_input=one_hot.detach()\n",
        "      return output\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUNDC0--SJcZ"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKsUk7uLSX2B"
      },
      "source": [
        "# unlike fully connceted or CNN model , we have to write an inference routine in case of sequence model.\n",
        "def infer(net, eng_word,shape,device ='cpu'):\n",
        "    # net.eval()\n",
        "    input_ = word_rep(eng_word,eng_alpha2index,device) # convert the name into one hot encoding.\n",
        "    outputs = net(input_,shape,device) # initilise the hidden layer.\n",
        "    \n",
        "    return outputs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF772OsESbQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2996c66-86b2-4655-b8eb-8616d44aa5d1"
      },
      "source": [
        "out = infer(net, 'INDIA', 30)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([6, 1, 27])\n",
            "Encoder output torch.Size([6, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder input  torch.Size([1, 1, 129])\n",
            "Decoder state  torch.Size([1, 1, 256])\n",
            "Decoder intermediate output  torch.Size([1, 1, 256])\n",
            "decoder output  torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl7FBb_USePd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40eddfca-c8ad-49c8-bdd9-eb8f918a31bc"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) ५\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) ह\n",
            "torch.Size([1, 129]) ॻ\n",
            "torch.Size([1, 129]) ॰\n",
            "torch.Size([1, 129]) ॰\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) ह\n",
            "torch.Size([1, 129]) ॻ\n",
            "torch.Size([1, 129]) ॰\n",
            "torch.Size([1, 129]) ॰\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) ह\n",
            "torch.Size([1, 129]) ॻ\n",
            "torch.Size([1, 129]) ॰\n",
            "torch.Size([1, 129]) ॰\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) फ़\n",
            "torch.Size([1, 129]) ह\n",
            "torch.Size([1, 129]) ॻ\n",
            "torch.Size([1, 129]) ॰\n",
            "torch.Size([1, 129]) ॰\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G437_K_hEf_U"
      },
      "source": [
        "#**Encoder decoder with Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7DwGdgjEgyb"
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHAR, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VBMedZXE736"
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yHnJU5HE-8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd094e0-5b56-431c-83ec-9928cc7c22e2"
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTClMiF1FCkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718a8b97-7b19-4990-e64b-5a74be3ab71e"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) प\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) र\n",
            "torch.Size([1, 129]) र\n",
            "torch.Size([1, 129]) ॾ\n",
            "torch.Size([1, 129]) ॾ\n",
            "torch.Size([1, 129]) ॾ\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ू\n",
            "torch.Size([1, 129]) ू\n",
            "torch.Size([1, 129]) ॴ\n",
            "torch.Size([1, 129]) ू\n",
            "torch.Size([1, 129]) ॴ\n",
            "torch.Size([1, 129]) े\n",
            "torch.Size([1, 129]) ॖ\n",
            "torch.Size([1, 129]) ॖ\n",
            "torch.Size([1, 129]) ॾ\n",
            "torch.Size([1, 129]) ऀ\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ड\n",
            "torch.Size([1, 129]) ू\n",
            "torch.Size([1, 129]) ू\n",
            "torch.Size([1, 129]) ॴ\n",
            "torch.Size([1, 129]) ू\n",
            "torch.Size([1, 129]) ॴ\n",
            "torch.Size([1, 129]) े\n",
            "torch.Size([1, 129]) ॖ\n",
            "torch.Size([1, 129]) ॖ\n",
            "torch.Size([1, 129]) ॾ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qb5YIRwTCSR"
      },
      "source": [
        "#**TRAINING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEWVs2glTIzX"
      },
      "source": [
        "**CORE TRAINER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEUx5iE4S1si"
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_dl.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLCXL2Z0T1Ka"
      },
      "source": [
        "**TRAIN HELPER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypZf78lUTy2n"
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrM5upOHUN4d"
      },
      "source": [
        "**TRAINING WITHOUT ATTENTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNyNfPXuUI40"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "V_QAcvOWUXay",
        "outputId": "b7654bc2-b742-4859-d300-8ce025b1e5ed"
      },
      "source": [
        "train_setup(net, lr=0.01, n_batches=2500, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 2499 Loss 0.09170868992805481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.50477791, 0.47074631, ..., 0.09171352, 0.09170869,\n",
              "       0.09170114])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s58BQaRyEY2D"
      },
      "source": [
        "#**Training with Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAVndD7gEYdc"
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExYH_XkFFhFC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "db5ca7a1-175a-4542-dc02-a3434b036346"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.01, n_batches=2500, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 459 Loss 0.10486796498298645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-baf88d5c3741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-a6aff6a6c25d>\u001b[0m in \u001b[0;36mtrain_setup\u001b[0;34m(net, lr, n_batches, batch_size, momentum, display_freq, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_force\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mteacher_force_upto\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdisplay_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdisplay_freq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-c36550066b80>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(net, opt, criterion, batch_size, device, teacher_force)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X-xG64nW4w5"
      },
      "source": [
        "#**INFERENCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX3fHUFeUuHK"
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_dl)):\n",
        "        eng, hindi = test_dl[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_dl)\n",
        "    return accuracy"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiXuy2cwYNTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7923e2-2f00-49f5-ab0f-305a78158139"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "#accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "#print('Accuracy with attention with lr=0.01 ', accuracy_attn)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  71.10677156177154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGoUDxJ1YSvs"
      },
      "source": [
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy with attention with lr=0.001 ', accuracy_attn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D94_mfuHPRO5"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention lr=0.01', accuracy)\n",
        "print('Accuracy with attention with lr=0.001 ', accuracy_attn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzmhDKFf7Pax"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2500, batch_size = 64, momentum=0.7,display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSJwJW4u76Jd"
      },
      "source": [
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "\n",
        "print('Accuracy with attention with lr=0.001,momentum=0.7:  ', accuracy_attn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4lbRdMQ79hn"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2500, batch_size = 64, momentum=1,display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6jQgJn9FJfc"
      },
      "source": [
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "\n",
        "print('Accuracy with attention with lr=0.001,momentum=1:  ', accuracy_attn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffadIwLqOOPq"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2500, batch_size = 64, momentum=0.9,display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pacHVqXmFLk_"
      },
      "source": [
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "\n",
        "print('Accuracy with attention with lr=0.001,momentum=0.9:  ', accuracy_attn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3dHuj5xQXoK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}